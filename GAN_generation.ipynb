{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Unique Artworks using GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs are a class of deep neural networks consisting of two neural networks competing against each other. We have the generator and discriminator.\n",
    "In this tutorial, we will be generating unique artworks using GANs. These artworks can be used as wall canvas, graffitis or even album covers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import helper\n",
    "from glob import glob\n",
    "import pickle as pkl\n",
    "import scipy.misc\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "\n",
    "# We will be using tensorflow v1 \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "preprocess = False # change if converting image size\n",
    "from_checkpoint = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "- We are using the [wikiarts](https://www.wikiart.org/en/paintings-by-genre/abstract?select=featured#!#filterName:featured,viewType:masonry) data. Download the dataset [here](https://drive.google.com/file/d/18AX8LxqzbcBoW1PYKj_mz8R3EAp_q5wI/view?usp=sharing).\n",
    "- Change `do_preprocess = True` to resize the images.\n",
    "\n",
    "### Resize images to 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/' # Data\n",
    "resized_data_dir = \"./resized_data\"# Resized data\n",
    "\n",
    "if preprocess == True:\n",
    "    # Create resized folder if not exist\n",
    "    if not os.path.exists(resized_data_dir):\n",
    "        os.mkdir(resized_data_dir)\n",
    "\n",
    "    for each in os.listdir(data_dir):\n",
    "        # Read the image\n",
    "        image = cv2.imread(os.path.join(data_dir, each))\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        cv2.imwrite(os.path.join(resized_data_dir, each), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images = 5\n",
    "data_images = helper.get_batch(glob(os.path.join(resized_data_dir, '*.jpg'))[:show_images], 64, 64, 'RGB')\n",
    "plt.imshow(helper.images_square_grid(data_images, 'RGB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the network\n",
    "Create TF placeholders for the Neural Network:\n",
    "- Real input images placeholder `real_dim`.\n",
    "- Z input placeholder `z_dim`.\n",
    "- Learning rate G placeholder.\n",
    "- Learning rate D placeholder.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_model_inputs(real_dim, z_dim):\n",
    "    \"\"\"\n",
    "    Create the inputs for the model\n",
    "    :param real_dim: tuple containing width, height and channels\n",
    "    :param z_dim: The dimension of Z\n",
    "    :return: Tuple of (tensor of real input images, tensor of z data, learning rate G, learning rate D)\n",
    "    \"\"\"\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
    "    learning_rate_G = tf.placeholder(tf.float32, name=\"learning_rate_G\")\n",
    "    learning_rate_D = tf.placeholder(tf.float32, name=\"learning_rate_D\")\n",
    "    \n",
    "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Generator Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, output_channel_dim, is_train=True):\n",
    "    ''' Building the generator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        z : Input tensor for the generator\n",
    "        output_channel_dim : Shape of the generator output\n",
    "        n_units : Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out: \n",
    "    '''\n",
    "    with tf.variable_scope(\"generator\", reuse= not is_train):\n",
    "        \n",
    "        # First FC layer --> 8x8x1024\n",
    "        fc1 = tf.layers.dense(z, 8*8*1024)\n",
    "        \n",
    "        # Reshape the layer\n",
    "        fc1 = tf.reshape(fc1, (-1, 8, 8, 1024))\n",
    "        \n",
    "        # Leaky ReLU Activation\n",
    "        fc1 = tf.nn.leaky_relu(fc1, alpha=alpha)\n",
    "\n",
    "        \n",
    "        # Transposed conv 1 --> BatchNorm --> LeakyReLU\n",
    "        # 8x8x1024 --> 16x16x512\n",
    "        trans_conv1 = tf.layers.conv2d_transpose(inputs = fc1,\n",
    "                                  filters = 512,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv1\")\n",
    "        \n",
    "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1, training=is_train, epsilon=1e-5, name=\"batch_trans_conv1\")\n",
    "       \n",
    "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1, alpha=alpha, name=\"trans_conv1_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 2 --> BatchNorm --> LeakyReLU\n",
    "        # 16x16x512 --> 32x32x256\n",
    "        trans_conv2 = tf.layers.conv2d_transpose(inputs = trans_conv1_out,\n",
    "                                  filters = 256,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv2\")\n",
    "        \n",
    "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2, training=is_train, epsilon=1e-5, name=\"batch_trans_conv2\")\n",
    "       \n",
    "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2, alpha=alpha, name=\"trans_conv2_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 3 --> BatchNorm --> LeakyReLU\n",
    "        # 32x32x256 --> 64x64x128\n",
    "        trans_conv3 = tf.layers.conv2d_transpose(inputs = trans_conv2_out,\n",
    "                                  filters = 128,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv3\")\n",
    "        \n",
    "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3, training=is_train, epsilon=1e-5, name=\"batch_trans_conv3\")\n",
    "       \n",
    "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3, alpha=alpha, name=\"trans_conv3_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 4 --> BatchNorm --> LeakyReLU\n",
    "        # 64x64x128 --> 128x128x64\n",
    "        trans_conv4 = tf.layers.conv2d_transpose(inputs = trans_conv3_out,\n",
    "                                  filters = 64,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv4\")\n",
    "        \n",
    "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4, training=is_train, epsilon=1e-5, name=\"batch_trans_conv4\")\n",
    "       \n",
    "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4, alpha=alpha, name=\"trans_conv4_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 5 --> tanh\n",
    "        # 128x128x64 --> 128x128x3\n",
    "        logits = tf.layers.conv2d_transpose(inputs = trans_conv4_out,\n",
    "                                  filters = 3,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [1,1],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"logits\")\n",
    "         \n",
    "        out = tf.tanh(logits, name=\"out\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, is_reuse=False, alpha = 0.2):\n",
    "    ''' Build the discriminator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Input tensor for the discriminator\n",
    "        n_units: Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out, logits: \n",
    "    '''\n",
    "    with tf.variable_scope(\"discriminator\", reuse = is_reuse): \n",
    "        \n",
    "        # Input layer 128*128*3 --> 64x64x64\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv1 = tf.layers.conv2d(inputs = x,\n",
    "                                filters = 64,\n",
    "                                kernel_size = [5,5],\n",
    "                                strides = [2,2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv1')\n",
    "        \n",
    "        batch_norm1 = tf.layers.batch_normalization(conv1,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                     name = 'batch_norm1')\n",
    "\n",
    "        conv1_out = tf.nn.leaky_relu(batch_norm1, alpha=alpha, name=\"conv1_out\")\n",
    "        \n",
    "        \n",
    "        # 64x64x64--> 32x32x128\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv2 = tf.layers.conv2d(inputs = conv1_out,\n",
    "                                filters = 128,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv2')\n",
    "        \n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                     name = 'batch_norm2')\n",
    "        \n",
    "        conv2_out = tf.nn.leaky_relu(batch_norm2, alpha=alpha, name=\"conv2_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 32x32x128 --> 16x16x256\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv3 = tf.layers.conv2d(inputs = conv2_out,\n",
    "                                filters = 256,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv3')\n",
    "        \n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm3')\n",
    "        \n",
    "        conv3_out = tf.nn.leaky_relu(batch_norm3, alpha=alpha, name=\"conv3_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 16x16x256 --> 16x16x512\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv4 = tf.layers.conv2d(inputs = conv3_out,\n",
    "                                filters = 512,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [1, 1],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv4')\n",
    "        \n",
    "        batch_norm4 = tf.layers.batch_normalization(conv4,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm4')\n",
    "        \n",
    "        conv4_out = tf.nn.leaky_relu(batch_norm4, alpha=alpha, name=\"conv4_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 16x16x512 --> 8x8x1024\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv5 = tf.layers.conv2d(inputs = conv4_out,\n",
    "                                filters = 1024,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv5')\n",
    "        \n",
    "        batch_norm5 = tf.layers.batch_normalization(conv5,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm5')\n",
    "        \n",
    "        conv5_out = tf.nn.leaky_relu(batch_norm5, alpha=alpha, name=\"conv5_out\")\n",
    "\n",
    "         \n",
    "        # Flatten it\n",
    "        flatten = tf.reshape(conv5_out, (-1, 8*8*1024))\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(inputs = flatten,\n",
    "                                units = 1,\n",
    "                                activation = None)\n",
    "        \n",
    "        \n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses in the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_model_loss(input_real, input_z, output_channel_dim, alpha):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    # Generator network here\n",
    "    g_model = generator(input_z, output_channel_dim)   \n",
    "    # g_model is the generator output\n",
    "    \n",
    "    # Discriminator network here\n",
    "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model,is_reuse=True, alpha=alpha)\n",
    "    \n",
    "    # Calculate losses\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n",
    "                                                          labels=tf.ones_like(d_model_real)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n",
    "                                                          labels=tf.zeros_like(d_model_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    g_loss = tf.reduce_mean(\n",
    "             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                     labels=tf.ones_like(d_model_fake)))\n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"    \n",
    "    # Get the trainable_variables, split into G and D parts\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    # Generator update\n",
    "    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n",
    "    \n",
    "    # Optimizers\n",
    "    with tf.control_dependencies(gen_updates):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate=lr_D, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate=lr_G, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        \n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show output\n",
    "\n",
    "We will be saving the output of the generator during training in order to determine how well the GANs is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_output(sess, n_images, input_z, out_channel_dim, image_mode, image_path, save, show):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    :param image_path: Path to save the image\n",
    "    \"\"\"\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = images_square_grid(samples, image_mode)\n",
    "    \n",
    "    if save == True:\n",
    "        # Save image\n",
    "        images_grid.save(image_path, 'JPEG')\n",
    "    \n",
    "    if show == True:\n",
    "        plt.imshow(images_grid, cmap=cmap)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We will be training the model with the hyperparameters such as epochs, batch size, learning rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch, batch_size, z_dim, learning_rate_D, learning_rate_G, beta1, get_batches, data_shape, data_image_mode, alpha):\n",
    "    \"\"\"\n",
    "    Training the GAN model\n",
    "    :param epoch: Number of epochs\n",
    "    :param batch_size: Batch Size\n",
    "    :param z_dim: Z dimension\n",
    "    :param learning_rate: Learning Rate\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :param get_batches: Function to get batches\n",
    "    :param data_shape: Shape of the data\n",
    "    :param data_image_mode: The image mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    # Create our input placeholders\n",
    "    input_images, input_z, lr_G, lr_D = gan_model_inputs(data_shape[1:], z_dim)\n",
    "        \n",
    "    # Losses\n",
    "    d_loss, g_loss = gan_model_loss(input_images, input_z, data_shape[3], alpha)\n",
    "    \n",
    "    # Optimizers\n",
    "    d_opt, g_opt = gan_model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    version = \"firstTrain\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Saver\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        num_epoch = 0\n",
    "        print(\"Starting the model training...\")\n",
    "        if from_checkpoint == True:\n",
    "            saver.restore(sess, \"./models/model.ckpt\")\n",
    "            # Save the generator output\n",
    "            generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False)\n",
    "            \n",
    "        else:\n",
    "            for epoch_i in range(epoch):        \n",
    "                num_epoch += 1\n",
    "                print(\"Training model for epoch_\", epoch_i)\n",
    "\n",
    "                if num_epoch % 5 == 0:\n",
    "\n",
    "                    # Save model every 5 epochs\n",
    "                    save_path = saver.save(sess, \"./models/model.ckpt\")\n",
    "                    print(\"Model has been saved.\")\n",
    "\n",
    "                for batch_images in get_batches(batch_size):\n",
    "                    # Random noise\n",
    "                    batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "                    # Run optimizers\n",
    "                    _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: learning_rate_D})\n",
    "                    _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: learning_rate_G})\n",
    "\n",
    "                    if i % 10 == 0:\n",
    "\n",
    "                        train_loss_d = d_loss.eval({input_z: batch_z, input_images: batch_images})\n",
    "                        train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "                        # Save it\n",
    "                        image_name = str(i) + \".jpg\"\n",
    "                        image_path = \"./images/epoch_\" + epoch_i + \"/\" + image_name\n",
    "                        # Save the generator output\n",
    "                        generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False) \n",
    "\n",
    "                    # Print every 5 epochs (for stability overwize the jupyter notebook will bug)\n",
    "                    if i % 1500 == 0:\n",
    "\n",
    "                        image_name = str(i) + \".jpg\"\n",
    "                        image_path = \"./images/epoch_\" + epoch_i + \"/\" + image_name\n",
    "                        print(\"Epoch {}/{}...\".format(epoch_i+1, epochs),\n",
    "                              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                              \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                        # Show the generator output\n",
    "                        generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, False, True)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Hyperparameters\n",
    "\n",
    "Like most neural networks, GANs are <b> very sensitive to hyperparemeters </b>\n",
    "In general, the discriminator loss around 0.3 determines that it is correctly classifying images as fake or real about 50% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size input image for discriminator\n",
    "img_size = (128,128,3)\n",
    "\n",
    "# Size of latent (noise) vector to generator\n",
    "z_dim = 100 \n",
    "\n",
    "# Learning ratess\n",
    "learning_rate_D =  .00005 \n",
    "learning_rate_G = 2e-4 \n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "# Number of epochs\n",
    "num_epochs = 200\n",
    "\n",
    "alpha = 0.2\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_dataset = helper.Dataset(glob(os.path.join(resized_data_dir, '*.jpg')))\n",
    "\n",
    "# Train the model\n",
    "with tf.Graph().as_default():\n",
    "    train_model(num_epochs, batch_size, z_dim, learning_rate_D, learning_rate_G, beta1, training_dataset.get_batches,\n",
    "          dataset.shape, dataset.image_mode, alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images = 5\n",
    "# Plot the images from last epoch\n",
    "data_images = helper.get_batch(glob(os.path.join(\"./images/epoch_\" + num_epochs +\"/\", '*.jpg'))[:show_images], 64, 64, 'RGB')\n",
    "plt.imshow(helper.images_square_grid(data_images, 'RGB'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
